# ExpandScreen 设计文档

## 文档信息
- **版本**: v1.0
- **创建日期**: 2026-01-22
- **最后更新**: 2026-01-22

---

## 目录
1. [系统架构设计](#1-系统架构设计)
2. [Windows客户端设计](#2-windows客户端设计)
3. [Android客户端设计](#3-android客户端设计)
4. [通信协议设计](#4-通信协议设计)
5. [数据库设计](#5-数据库设计)
6. [核心模块详细设计](#6-核心模块详细设计)
7. [性能优化方案](#7-性能优化方案)
8. [安全设计](#8-安全设计)

---

## 1. 系统架构设计

### 1.1 总体架构

```
┌─────────────────────────────────────────────────────────────┐
│                     Windows 客户端                           │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │  UI 层      │  │  业务逻辑层  │  │  服务层      │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
│         │                │                  │                │
│  ┌──────▼────────────────▼──────────────────▼──────┐        │
│  │           核心引擎 (Core Engine)                │        │
│  ├─────────────────────────────────────────────────┤        │
│  │ 虚拟显示驱动 │ 屏幕捕获 │ 视频编码 │ 网络管理   │        │
│  └─────────────────────────────────────────────────┘        │
└─────────────────────────────────────────────────────────────┘
                            │
                    ┌───────┴───────┐
                    │               │
              ┌─────▼─────┐   ┌────▼─────┐
              │ USB(ADB)  │   │ WiFi/LAN │
              └─────┬─────┘   └────┬─────┘
                    │               │
                    └───────┬───────┘
                            │
┌─────────────────────────────────────────────────────────────┐
│                    Android 客户端                            │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────────────┐        │
│  │           核心引擎 (Core Engine)                │        │
│  ├─────────────────────────────────────────────────┤        │
│  │ 网络接收 │ 视频解码 │ 渲染引擎 │ 触控采集       │        │
│  └─────────────────────────────────────────────────┘        │
│         │                │                  │                │
│  ┌──────▼────────────────▼──────────────────▼──────┐        │
│  │  UI 层      │  │  业务逻辑层  │  │  服务层      │        │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 技术选型

#### Windows客户端
- **开发语言**: C++ / C# (.NET 6.0+)
- **UI框架**: WPF / WinUI 3
- **虚拟显示驱动**: IddCx (Indirect Display Driver)
- **屏幕捕获**: DXGI Desktop Duplication API
- **视频编码**: FFmpeg / NVENC / QuickSync
- **网络通信**: WebSocket (ws库) / TCP Socket
- **ADB通信**: adb.exe / USB驱动

#### Android客户端
- **开发语言**: Kotlin
- **UI框架**: Jetpack Compose
- **视频解码**: MediaCodec (硬件加速)
- **渲染**: OpenGL ES / Vulkan
- **网络通信**: OkHttp (WebSocket) / Socket
- **依赖注入**: Hilt
- **异步处理**: Kotlin Coroutines + Flow

---

## 2. Windows客户端设计

### 2.1 模块划分

```
ExpandScreen.Windows/
├── UI/                          # 用户界面层
│   ├── Views/                   # 视图
│   │   ├── MainWindow.xaml      # 主窗口
│   │   ├── SettingsWindow.xaml  # 设置窗口
│   │   └── TrayIcon.cs          # 系统托盘
│   └── ViewModels/              # 视图模型 (MVVM)
│       ├── MainViewModel.cs
│       └── SettingsViewModel.cs
│
├── Core/                        # 核心引擎
│   ├── DisplayDriver/           # 虚拟显示驱动
│   │   ├── VirtualDisplayManager.cs
│   │   └── DisplayDevice.cs
│   ├── Capture/                 # 屏幕捕获
│   │   ├── DesktopDuplicator.cs
│   │   └── FrameCapture.cs
│   ├── Encoder/                 # 视频编码
│   │   ├── IEncoder.cs
│   │   ├── FFmpegEncoder.cs
│   │   ├── NvencEncoder.cs
│   │   └── QuickSyncEncoder.cs
│   └── Network/                 # 网络管理
│       ├── ConnectionManager.cs
│       ├── UsbConnection.cs
│       └── WifiConnection.cs
│
├── Services/                    # 业务服务层
│   ├── DeviceService.cs         # 设备管理
│   ├── StreamingService.cs      # 流媒体服务
│   ├── InputService.cs          # 输入处理
│   └── ConfigService.cs         # 配置管理
│
├── Protocol/                    # 通信协议
│   ├── Messages/                # 消息定义
│   │   ├── ControlMessage.cs
│   │   ├── VideoFrame.cs
│   │   └── TouchEvent.cs
│   └── Serialization/           # 序列化
│       └── MessageSerializer.cs
│
└── Utils/                       # 工具类
    ├── Logger.cs
    └── PerformanceMonitor.cs
```

### 2.2 核心类设计

#### 2.2.1 VirtualDisplayManager（虚拟显示管理器）

```csharp
public class VirtualDisplayManager
{
    // 属性
    public List<VirtualDisplay> VirtualDisplays { get; private set; }
    public bool IsDriverInstalled { get; private set; }

    // 方法
    public async Task<bool> InstallDriverAsync();
    public async Task<VirtualDisplay> CreateDisplayAsync(DisplayConfig config);
    public async Task<bool> RemoveDisplayAsync(string displayId);
    public async Task<bool> UpdateDisplayModeAsync(string displayId, DisplayMode mode);
    public List<DisplayMode> GetSupportedModes(string displayId);
}

public class DisplayConfig
{
    public int Width { get; set; }
    public int Height { get; set; }
    public int RefreshRate { get; set; }
    public DisplayOrientation Orientation { get; set; }
}
```

#### 2.2.2 DesktopDuplicator（桌面复制器）

```csharp
public class DesktopDuplicator : IDisposable
{
    // 属性
    public int TargetMonitorIndex { get; set; }
    public bool IsCapturing { get; private set; }

    // 方法
    public async Task<bool> InitializeAsync();
    public async Task<CapturedFrame> CaptureFrameAsync();
    public void StartCapture(Action<CapturedFrame> onFrameCaptured);
    public void StopCapture();
    public void Dispose();
}

public class CapturedFrame
{
    public byte[] Data { get; set; }
    public int Width { get; set; }
    public int Height { get; set; }
    public PixelFormat Format { get; set; }
    public long Timestamp { get; set; }
    public Rectangle DirtyRegion { get; set; }  // 脏矩形优化
}
```

#### 2.2.3 VideoEncoder（视频编码器）

```csharp
public interface IEncoder
{
    Task<bool> InitializeAsync(EncoderConfig config);
    Task<EncodedFrame> EncodeAsync(CapturedFrame frame);
    void Release();
}

public class EncoderConfig
{
    public int Width { get; set; }
    public int Height { get; set; }
    public int Bitrate { get; set; }
    public int Framerate { get; set; }
    public CodecType Codec { get; set; }  // H264, H265, VP9
    public EncoderPreset Preset { get; set; }  // UltraFast, Fast, Medium, Slow
    public bool UseHardwareAcceleration { get; set; }
}

public class EncodedFrame
{
    public byte[] Data { get; set; }
    public long Timestamp { get; set; }
    public bool IsKeyFrame { get; set; }
    public int Size { get; set; }
}
```

#### 2.2.4 ConnectionManager（连接管理器）

```csharp
public class ConnectionManager
{
    // 事件
    public event EventHandler<DeviceConnectedEventArgs> DeviceConnected;
    public event EventHandler<DeviceDisconnectedEventArgs> DeviceDisconnected;
    public event EventHandler<DataReceivedEventArgs> DataReceived;

    // 方法
    public async Task<List<AndroidDevice>> DiscoverDevicesAsync();
    public async Task<bool> ConnectAsync(AndroidDevice device, ConnectionType type);
    public async Task<bool> DisconnectAsync(string deviceId);
    public async Task<bool> SendDataAsync(string deviceId, byte[] data);
    public ConnectionStatus GetConnectionStatus(string deviceId);
}

public class AndroidDevice
{
    public string Id { get; set; }
    public string Name { get; set; }
    public string Model { get; set; }
    public string IpAddress { get; set; }
    public ConnectionType SupportedConnections { get; set; }
    public DeviceInfo Info { get; set; }
}
```

#### 2.2.5 InputService（输入处理服务）

```csharp
public class InputService
{
    // 方法
    public void InjectTouchEvent(TouchEvent touchEvent);
    public void InjectMouseEvent(MouseEvent mouseEvent);
    public void InjectKeyboardEvent(KeyboardEvent keyEvent);

    // 坐标转换
    private Point TransformCoordinates(Point androidCoord, Rectangle displayBounds);
}

public class TouchEvent
{
    public int PointerId { get; set; }
    public float X { get; set; }
    public float Y { get; set; }
    public TouchAction Action { get; set; }  // Down, Move, Up
    public long Timestamp { get; set; }
}
```

### 2.3 数据流设计

```
屏幕捕获线程:
DesktopDuplicator (60fps)
    → CapturedFrame Buffer (队列)
    → VideoEncoder
    → EncodedFrame Buffer
    → NetworkSender
    → Android设备

触控接收线程:
NetworkReceiver
    → TouchEvent Buffer
    → InputService
    → Windows Input Injection
```

---

## 3. Android客户端设计

### 3.1 模块划分

```
app/
└── src/main/java/com/expandscreen/android/
    ├── ui/                         # UI层
    │   ├── main/                   # 主界面
    │   │   ├── MainActivity.kt
    │   │   └── MainViewModel.kt
    │   ├── display/                # 显示界面
    │   │   ├── DisplayActivity.kt
    │   │   └── DisplayViewModel.kt
    │   ├── settings/               # 设置界面
    │   │   └── SettingsFragment.kt
    │   └── connection/             # 连接界面
    │       └── ConnectionFragment.kt
    │
    ├── core/                       # 核心引擎
    │   ├── network/                # 网络层
    │   │   ├── NetworkManager.kt
    │   │   ├── WebSocketClient.kt
    │   │   └── UsbConnection.kt
    │   ├── decoder/                # 视频解码
    │   │   ├── VideoDecoder.kt
    │   │   └── HardwareDecoder.kt
    │   ├── renderer/               # 渲染引擎
    │   │   ├── VideoRenderer.kt
    │   │   ├── GLRenderer.kt
    │   │   └── SurfaceRenderer.kt
    │   └── input/                  # 触控采集
    │       └── TouchProcessor.kt
    │
    ├── service/                    # 后台服务
    │   └── DisplayService.kt       # 显示服务
    │
    ├── protocol/                   # 通信协议
    │   ├── messages/               # 消息定义
    │   │   ├── ControlMessage.kt
    │   │   ├── VideoFrame.kt
    │   │   └── TouchEvent.kt
    │   └── serialization/          # 序列化
    │       └── MessageSerializer.kt
    │
    ├── data/                       # 数据层
    │   ├── repository/             # 数据仓库
    │   │   └── SettingsRepository.kt
    │   ├── local/                  # 本地存储
    │   │   └── PreferencesManager.kt
    │   └── model/                  # 数据模型
    │       └── DeviceConfig.kt
    │
    └── utils/                      # 工具类
        ├── Logger.kt
        └── PerformanceMonitor.kt
```

### 3.2 核心类设计

#### 3.2.1 VideoDecoder（视频解码器）

```kotlin
class VideoDecoder {
    private var mediaCodec: MediaCodec? = null
    private var surface: Surface? = null

    // 初始化解码器
    suspend fun initialize(config: DecoderConfig): Boolean

    // 解码视频帧
    suspend fun decode(encodedData: ByteArray): Boolean

    // 释放资源
    fun release()

    // 配置
    data class DecoderConfig(
        val width: Int,
        val height: Int,
        val codecType: CodecType,
        val surface: Surface
    )
}
```

#### 3.2.2 GLRenderer（OpenGL渲染器）

```kotlin
class GLRenderer : GLSurfaceView.Renderer {
    private var textureId: Int = 0
    private var surfaceTexture: SurfaceTexture? = null

    override fun onSurfaceCreated(gl: GL10?, config: EGLConfig?)
    override fun onSurfaceChanged(gl: GL10?, width: Int, height: Int)
    override fun onDrawFrame(gl: GL10?)

    // 获取用于解码器的Surface
    fun getDecoderSurface(): Surface

    // 更新纹理
    fun updateTexture()
}
```

#### 3.2.3 TouchProcessor（触控处理器）

```kotlin
class TouchProcessor(private val networkManager: NetworkManager) {

    // 处理触摸事件
    fun processTouchEvent(event: MotionEvent) {
        when (event.actionMasked) {
            MotionEvent.ACTION_DOWN,
            MotionEvent.ACTION_POINTER_DOWN -> handleTouchDown(event)
            MotionEvent.ACTION_MOVE -> handleTouchMove(event)
            MotionEvent.ACTION_UP,
            MotionEvent.ACTION_POINTER_UP -> handleTouchUp(event)
        }
    }

    private fun handleTouchDown(event: MotionEvent)
    private fun handleTouchMove(event: MotionEvent)
    private fun handleTouchUp(event: MotionEvent)

    // 发送触控事件到Windows
    private suspend fun sendTouchEvent(touchEvent: TouchEvent)
}
```

#### 3.2.4 NetworkManager（网络管理器）

```kotlin
class NetworkManager {
    private var webSocketClient: WebSocketClient? = null
    private var usbConnection: UsbConnection? = null

    // 连接流
    private val _connectionState = MutableStateFlow<ConnectionState>(ConnectionState.Disconnected)
    val connectionState: StateFlow<ConnectionState> = _connectionState.asStateFlow()

    // 数据接收流
    private val _receivedData = MutableSharedFlow<ByteArray>()
    val receivedData: SharedFlow<ByteArray> = _receivedData.asSharedFlow()

    // 连接方法
    suspend fun connectViaWifi(ipAddress: String, port: Int): Result<Unit>
    suspend fun connectViaUsb(): Result<Unit>
    suspend fun disconnect()

    // 发送数据
    suspend fun sendData(data: ByteArray): Result<Unit>

    // 设备发现
    suspend fun discoverDevices(): List<WindowsDevice>
}

sealed class ConnectionState {
    object Disconnected : ConnectionState()
    object Connecting : ConnectionState()
    data class Connected(val device: WindowsDevice) : ConnectionState()
    data class Error(val message: String) : ConnectionState()
}
```

#### 3.2.5 DisplayService（显示服务）

```kotlin
class DisplayService : Service() {
    private lateinit var videoDecoder: VideoDecoder
    private lateinit var networkManager: NetworkManager
    private lateinit var wakeLock: PowerManager.WakeLock

    override fun onCreate()
    override fun onStartCommand(intent: Intent?, flags: Int, startId: Int): Int
    override fun onBind(intent: Intent?): IBinder?
    override fun onDestroy()

    // 启动前台服务
    private fun startForegroundService()

    // 数据处理循环
    private suspend fun dataProcessingLoop()
}
```

### 3.3 Activity生命周期管理

```kotlin
class DisplayActivity : AppCompatActivity() {

    override fun onCreate(savedInstanceState: Bundle?) {
        // 1. 设置全屏
        setFullScreen()

        // 2. 初始化渲染器
        initializeRenderer()

        // 3. 启动显示服务
        startDisplayService()

        // 4. 保持屏幕常亮
        keepScreenOn()
    }

    override fun onResume() {
        // 恢复解码和渲染
    }

    override fun onPause() {
        // 暂停解码（根据设置）
    }

    override fun onDestroy() {
        // 释放所有资源
        releaseResources()
    }
}
```

---

## 4. 通信协议设计

### 4.1 协议栈设计

```
┌─────────────────────────────────────┐
│     应用层 (Application Layer)      │  消息类型、序列化
├─────────────────────────────────────┤
│     传输层 (Transport Layer)        │  WebSocket / TCP
├─────────────────────────────────────┤
│     网络层 (Network Layer)          │  IP (WiFi / USB网络)
├─────────────────────────────────────┤
│     链路层 (Link Layer)             │  WiFi / USB
└─────────────────────────────────────┘
```

### 4.2 消息格式定义

#### 4.2.1 消息头格式

```
┌────────────────────────────────────────────────────┐
│  Magic (4 bytes) │ 'EXSC' (0x45585343)             │
├────────────────────────────────────────────────────┤
│  Version (2 bytes) │ 协议版本 (目前为 0x0001)      │
├────────────────────────────────────────────────────┤
│  MessageType (2 bytes) │ 消息类型                  │
├────────────────────────────────────────────────────┤
│  PayloadLength (4 bytes) │ 负载长度                │
├────────────────────────────────────────────────────┤
│  Timestamp (8 bytes) │ 时间戳 (Unix毫秒)           │
├────────────────────────────────────────────────────┤
│  Reserved (4 bytes) │ 保留字段                     │
├────────────────────────────────────────────────────┤
│  Payload (N bytes) │ 消息负载                      │
└────────────────────────────────────────────────────┘
Total Header Size: 24 bytes
```

#### 4.2.2 消息类型定义

```csharp
public enum MessageType : ushort
{
    // 控制消息 (0x0000 - 0x00FF)
    Handshake = 0x0001,          // 握手
    HandshakeAck = 0x0002,       // 握手确认
    Heartbeat = 0x0003,          // 心跳
    HeartbeatAck = 0x0004,       // 心跳确认
    Disconnect = 0x0005,         // 断开连接

    // 配置消息 (0x0100 - 0x01FF)
    ConfigRequest = 0x0101,      // 配置请求
    ConfigResponse = 0x0102,     // 配置响应
    DisplayModeChange = 0x0103,  // 显示模式变更

    // 视频流消息 (0x0200 - 0x02FF)
    VideoFrame = 0x0201,         // 视频帧
    VideoConfigUpdate = 0x0202,  // 视频配置更新
    KeyFrameRequest = 0x0203,    // 关键帧请求

    // 输入消息 (0x0300 - 0x03FF)
    TouchEvent = 0x0301,         // 触摸事件
    KeyboardEvent = 0x0302,      // 键盘事件
    MouseEvent = 0x0303,         // 鼠标事件

    // 音频消息 (0x0400 - 0x04FF)
    AudioFrame = 0x0401,         // 音频帧
    AudioConfigUpdate = 0x0402,  // 音频配置更新

    // 状态消息 (0x0500 - 0x05FF)
    StatusReport = 0x0501,       // 状态报告
    PerformanceMetrics = 0x0502, // 性能指标
    ErrorReport = 0x0503,        // 错误报告
}
```

#### 4.2.3 具体消息定义

**握手消息 (Handshake)**
```json
{
  "messageType": "Handshake",
  "payload": {
    "deviceId": "android_device_12345",
    "deviceName": "Samsung Galaxy Tab S8",
    "deviceModel": "SM-X906B",
    "androidVersion": "13",
    "screenWidth": 2560,
    "screenHeight": 1600,
    "screenDpi": 320,
    "supportedCodecs": ["H264", "H265"],
    "supportedFeatures": ["multitouch", "audio", "rotation"],
    "protocolVersion": 1
  }
}
```

**握手确认消息 (HandshakeAck)**
```json
{
  "messageType": "HandshakeAck",
  "payload": {
    "sessionId": "session_67890",
    "serverVersion": "1.0.0",
    "selectedCodec": "H264",
    "videoConfig": {
      "width": 2560,
      "height": 1600,
      "framerate": 60,
      "bitrate": 8000000,
      "keyframeInterval": 30
    },
    "status": "success"
  }
}
```

**视频帧消息 (VideoFrame)**
```
Header (24 bytes) + Payload:
{
  "frameNumber": 12345,
  "timestamp": 1674567890123,
  "isKeyFrame": true,
  "encodedDataSize": 65536,
  "encodedData": [binary data]
}
```

**触摸事件消息 (TouchEvent)**
```json
{
  "messageType": "TouchEvent",
  "payload": {
    "pointers": [
      {
        "pointerId": 0,
        "x": 1280.5,
        "y": 800.0,
        "pressure": 0.8,
        "action": "move"
      }
    ],
    "timestamp": 1674567890123
  }
}
```

### 4.3 连接建立流程

#### 4.3.1 WiFi连接流程

```
Android设备                           Windows客户端
    │                                      │
    │────── 1. UDP广播 (发现) ─────────────>│
    │                                      │
    │<────── 2. 发现响应 ────────────────────│
    │                                      │
    │────── 3. TCP连接请求 ─────────────────>│
    │                                      │
    │<────── 4. TCP连接建立 ─────────────────│
    │                                      │
    │────── 5. WebSocket握手 ───────────────>│
    │                                      │
    │<────── 6. WebSocket握手确认 ───────────│
    │                                      │
    │────── 7. Handshake消息 ───────────────>│
    │                                      │
    │<────── 8. HandshakeAck消息 ────────────│
    │                                      │
    │<══════ 9. 开始视频流传输 ══════════════│
    │                                      │
```

#### 4.3.2 USB连接流程

```
Android设备                           Windows客户端
    │                                      │
    │────── 1. USB物理连接 ─────────────────>│
    │                                      │
    │<────── 2. ADB连接建立 ─────────────────│
    │                                      │
    │<────── 3. ADB端口转发 ─────────────────│
    │        (adb forward tcp:5555         │
    │         tcp:5555)                    │
    │                                      │
    │────── 4. TCP连接 (localhost:5555) ────>│
    │                                      │
    │────── 5. Handshake消息 ───────────────>│
    │                                      │
    │<────── 6. HandshakeAck消息 ────────────│
    │                                      │
    │<══════ 7. 开始视频流传输 ══════════════│
    │                                      │
```

### 4.4 心跳机制

```
间隔: 5秒
超时: 15秒 (3次心跳未响应视为断线)

Windows → Android: Heartbeat (包含性能统计)
Android → Windows: HeartbeatAck (包含设备状态)
```

### 4.5 流控机制

```kotlin
// 滑动窗口流控
class FlowControl {
    private val windowSize = 1024 * 1024 * 2  // 2MB窗口
    private var currentWindowUsed = 0

    fun canSendFrame(frameSize: Int): Boolean {
        return currentWindowUsed + frameSize <= windowSize
    }

    fun onFrameSent(frameSize: Int) {
        currentWindowUsed += frameSize
    }

    fun onFrameAcknowledged(frameSize: Int) {
        currentWindowUsed -= frameSize
    }
}
```

---

## 5. 数据库设计

### 5.1 Windows客户端数据库 (SQLite)

#### 表结构

**devices 表 (设备表)**
```sql
CREATE TABLE devices (
    device_id TEXT PRIMARY KEY,
    device_name TEXT NOT NULL,
    device_model TEXT,
    ip_address TEXT,
    last_connected DATETIME,
    connection_type TEXT,  -- 'usb' or 'wifi'
    is_favorite INTEGER DEFAULT 0,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

**connection_history 表 (连接历史)**
```sql
CREATE TABLE connection_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id TEXT,
    connection_type TEXT,
    connected_at DATETIME,
    disconnected_at DATETIME,
    duration INTEGER,  -- 秒
    average_latency INTEGER,  -- 毫秒
    average_fps REAL,
    FOREIGN KEY (device_id) REFERENCES devices(device_id)
);
```

**settings 表 (设置)**
```sql
CREATE TABLE settings (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

**display_profiles 表 (显示配置)**
```sql
CREATE TABLE display_profiles (
    profile_id INTEGER PRIMARY KEY AUTOINCREMENT,
    profile_name TEXT NOT NULL,
    width INTEGER NOT NULL,
    height INTEGER NOT NULL,
    refresh_rate INTEGER NOT NULL,
    bitrate INTEGER NOT NULL,
    codec TEXT NOT NULL,
    is_default INTEGER DEFAULT 0
);
```

### 5.2 Android客户端数据存储 (SharedPreferences + Room)

#### Room实体定义

```kotlin
@Entity(tableName = "windows_devices")
data class WindowsDeviceEntity(
    @PrimaryKey val deviceId: String,
    val deviceName: String,
    val ipAddress: String?,
    val lastConnected: Long,
    val connectionType: String,
    val isFavorite: Boolean = false
)

@Entity(tableName = "connection_logs")
data class ConnectionLogEntity(
    @PrimaryKey(autoGenerate = true) val id: Long = 0,
    val deviceId: String,
    val connectedAt: Long,
    val disconnectedAt: Long?,
    val averageLatency: Int,
    val averageFps: Float
)

@Dao
interface DeviceDao {
    @Query("SELECT * FROM windows_devices ORDER BY last_connected DESC")
    fun getAllDevices(): Flow<List<WindowsDeviceEntity>>

    @Insert(onConflict = OnConflictStrategy.REPLACE)
    suspend fun insertDevice(device: WindowsDeviceEntity)

    @Query("SELECT * FROM windows_devices WHERE is_favorite = 1")
    fun getFavoriteDevices(): Flow<List<WindowsDeviceEntity>>
}
```

---

## 6. 核心模块详细设计

### 6.1 虚拟显示驱动实现

#### 6.1.1 IddCx驱动架构

```
┌─────────────────────────────────────────┐
│         Windows Display System          │
├─────────────────────────────────────────┤
│              IddCx框架                   │
├─────────────────────────────────────────┤
│        ExpandScreen驱动 (.sys)          │
│  ┌─────────────────────────────────┐   │
│  │  - 设备初始化                    │   │
│  │  - 模式列表管理                  │   │
│  │  - 帧提交处理                    │   │
│  │  - EDID模拟                      │   │
│  └─────────────────────────────────┘   │
└─────────────────────────────────────────┘
         ↕ IOCTL通信
┌─────────────────────────────────────────┐
│      ExpandScreen用户态程序             │
└─────────────────────────────────────────┘
```

#### 6.1.2 驱动核心代码设计

```cpp
// 驱动入口点
extern "C" NTSTATUS DriverEntry(
    _In_ PDRIVER_OBJECT  DriverObject,
    _In_ PUNICODE_STRING RegistryPath)
{
    WDF_DRIVER_CONFIG config;
    WDF_DRIVER_CONFIG_INIT(&config, ExpandScreenDeviceAdd);

    NTSTATUS status = WdfDriverCreate(
        DriverObject,
        RegistryPath,
        WDF_NO_OBJECT_ATTRIBUTES,
        &config,
        WDF_NO_HANDLE);

    return status;
}

// 设备添加
NTSTATUS ExpandScreenDeviceAdd(
    _In_ WDFDRIVER Driver,
    _Inout_ PWDFDEVICE_INIT DeviceInit)
{
    // 初始化IddCx
    IDDCX_ADAPTER adapter = {};

    // 设置回调函数
    IddCxAdapterInitAsync(&init, ...);

    return STATUS_SUCCESS;
}

// 支持的显示模式
const DISPLAYCONFIG_VIDEO_SIGNAL_INFO SupportedModes[] = {
    // 1920x1080 @ 60Hz
    CreateMode(1920, 1080, 60),
    // 2560x1600 @ 60Hz
    CreateMode(2560, 1600, 60),
    // 1920x1080 @ 120Hz
    CreateMode(1920, 1080, 120),
};
```

### 6.2 屏幕捕获实现

#### 6.2.1 DXGI Desktop Duplication实现

```csharp
public class DesktopDuplicator
{
    private IDXGIOutputDuplication _deskDupl;
    private ID3D11Device _device;
    private ID3D11DeviceContext _context;

    public bool Initialize(int monitorIndex)
    {
        // 1. 创建D3D11设备
        D3D11CreateDevice(..., out _device);
        _device.GetImmediateContext(out _context);

        // 2. 获取DXGI输出
        var output = GetOutputByIndex(monitorIndex);

        // 3. 创建桌面复制
        var output1 = output.QueryInterface<IDXGIOutput1>();
        output1.DuplicateOutput(_device, out _deskDupl);

        return true;
    }

    public CapturedFrame CaptureFrame()
    {
        // 1. 获取帧
        _deskDupl.AcquireNextFrame(
            timeoutMs: 16,  // ~60fps
            out var frameInfo,
            out var desktopResource);

        try
        {
            // 2. 只处理有变化的帧
            if (frameInfo.TotalMetadataBufferSize == 0)
            {
                return null;
            }

            // 3. 转换为Texture2D
            var texture = desktopResource.QueryInterface<ID3D11Texture2D>();

            // 4. 复制到CPU可访问的纹理
            var stagingTexture = CreateStagingTexture(texture);
            _context.CopyResource(stagingTexture, texture);

            // 5. 映射到CPU内存
            var mappedResource = _context.Map(stagingTexture, ...);

            // 6. 创建帧对象
            var frame = new CapturedFrame
            {
                Data = CopyData(mappedResource),
                Width = desc.Width,
                Height = desc.Height,
                Timestamp = GetTimestamp(),
                DirtyRects = GetDirtyRects(frameInfo)  // 优化：只编码变化区域
            };

            _context.Unmap(stagingTexture);

            return frame;
        }
        finally
        {
            _deskDupl.ReleaseFrame();
            desktopResource?.Dispose();
        }
    }
}
```

### 6.3 视频编码实现

#### 6.3.1 FFmpeg软件编码

```csharp
public class FFmpegEncoder : IEncoder
{
    private AVCodecContext* _codecContext;
    private SwsContext* _swsContext;

    public bool Initialize(EncoderConfig config)
    {
        // 1. 查找编码器
        var codec = ffmpeg.avcodec_find_encoder(AVCodecID.AV_CODEC_ID_H264);

        // 2. 创建编码器上下文
        _codecContext = ffmpeg.avcodec_alloc_context3(codec);

        // 3. 设置参数
        _codecContext->width = config.Width;
        _codecContext->height = config.Height;
        _codecContext->time_base = new AVRational { num = 1, den = config.Framerate };
        _codecContext->framerate = new AVRational { num = config.Framerate, den = 1 };
        _codecContext->bit_rate = config.Bitrate;
        _codecContext->gop_size = 30;  // 关键帧间隔
        _codecContext->max_b_frames = 0;  // 低延迟模式
        _codecContext->pix_fmt = AVPixelFormat.AV_PIX_FMT_YUV420P;

        // 4. 设置编码预设
        ffmpeg.av_opt_set(_codecContext->priv_data, "preset", "ultrafast", 0);
        ffmpeg.av_opt_set(_codecContext->priv_data, "tune", "zerolatency", 0);

        // 5. 打开编码器
        ffmpeg.avcodec_open2(_codecContext, codec, null);

        // 6. 创建像素格式转换器 (BGRA -> YUV420P)
        _swsContext = ffmpeg.sws_getContext(
            config.Width, config.Height, AVPixelFormat.AV_PIX_FMT_BGRA,
            config.Width, config.Height, AVPixelFormat.AV_PIX_FMT_YUV420P,
            ffmpeg.SWS_FAST_BILINEAR, null, null, null);

        return true;
    }

    public EncodedFrame Encode(CapturedFrame frame)
    {
        // 1. 转换像素格式
        var yuvFrame = ConvertToYUV420P(frame);

        // 2. 编码
        ffmpeg.avcodec_send_frame(_codecContext, yuvFrame);

        var packet = ffmpeg.av_packet_alloc();
        var ret = ffmpeg.avcodec_receive_packet(_codecContext, packet);

        if (ret == 0)
        {
            var encodedFrame = new EncodedFrame
            {
                Data = new byte[packet->size],
                Timestamp = frame.Timestamp,
                IsKeyFrame = (packet->flags & ffmpeg.AV_PKT_FLAG_KEY) != 0,
                Size = packet->size
            };

            Marshal.Copy((IntPtr)packet->data, encodedFrame.Data, 0, packet->size);
            ffmpeg.av_packet_free(&packet);

            return encodedFrame;
        }

        return null;
    }
}
```

#### 6.3.2 NVENC硬件编码

```csharp
public class NvencEncoder : IEncoder
{
    private IntPtr _encoder;
    private NV_ENC_INITIALIZE_PARAMS _initParams;

    public bool Initialize(EncoderConfig config)
    {
        // 1. 打开NVENC编码会话
        var result = NvEncOpenEncodeSessionEx(out _encoder);

        // 2. 设置编码参数
        _initParams = new NV_ENC_INITIALIZE_PARAMS
        {
            encodeWidth = config.Width,
            encodeHeight = config.Height,
            darWidth = config.Width,
            darHeight = config.Height,
            frameRateNum = config.Framerate,
            frameRateDen = 1,
            enablePTD = 1,
            presetGUID = NV_ENC_PRESET_LOW_LATENCY_HP_GUID,  // 低延迟高性能
            encodeConfig = new NV_ENC_CONFIG
            {
                gopLength = 30,
                frameIntervalP = 1,
                rcParams = new NV_ENC_RC_PARAMS
                {
                    rateControlMode = NV_ENC_PARAMS_RC_MODE.NV_ENC_PARAMS_RC_CBR,
                    averageBitRate = config.Bitrate,
                    maxBitRate = config.Bitrate,
                    vbvBufferSize = config.Bitrate / config.Framerate * 2,
                }
            }
        };

        // 3. 初始化编码器
        NvEncInitializeEncoder(_encoder, ref _initParams);

        return true;
    }

    public EncodedFrame Encode(CapturedFrame frame)
    {
        // NVENC特定的编码逻辑
        // 使用GPU直接编码，避免CPU拷贝
        var encodedData = NvEncEncodePicture(_encoder, frame.Data);

        return new EncodedFrame
        {
            Data = encodedData,
            Timestamp = frame.Timestamp,
            IsKeyFrame = CheckKeyFrame(encodedData),
            Size = encodedData.Length
        };
    }
}
```

### 6.4 视频解码实现 (Android)

```kotlin
class HardwareDecoder(private val surface: Surface) {
    private var mediaCodec: MediaCodec? = null
    private val bufferInfo = MediaCodec.BufferInfo()

    fun initialize(width: Int, height: Int, codecType: String) {
        // 1. 创建解码器
        mediaCodec = MediaCodec.createDecoderByType(codecType)

        // 2. 配置解码器
        val format = MediaFormat.createVideoFormat(codecType, width, height).apply {
            setInteger(MediaFormat.KEY_LOW_LATENCY, 1)  // 低延迟模式
            setInteger(MediaFormat.KEY_PRIORITY, 0)  // 实时优先级
        }

        // 3. 配置输出到Surface
        mediaCodec?.configure(format, surface, null, 0)

        // 4. 启动解码器
        mediaCodec?.start()
    }

    suspend fun decode(encodedData: ByteArray): Boolean = withContext(Dispatchers.Default) {
        try {
            // 1. 获取输入缓冲区
            val inputBufferIndex = mediaCodec?.dequeueInputBuffer(TIMEOUT_US) ?: -1

            if (inputBufferIndex >= 0) {
                // 2. 填充数据
                val inputBuffer = mediaCodec?.getInputBuffer(inputBufferIndex)
                inputBuffer?.clear()
                inputBuffer?.put(encodedData)

                // 3. 提交到解码器
                mediaCodec?.queueInputBuffer(
                    inputBufferIndex,
                    0,
                    encodedData.size,
                    System.nanoTime() / 1000,  // 微秒时间戳
                    0
                )
            }

            // 4. 获取解码后的帧
            val outputBufferIndex = mediaCodec?.dequeueOutputBuffer(bufferInfo, TIMEOUT_US) ?: -1

            if (outputBufferIndex >= 0) {
                // 5. 渲染到Surface
                mediaCodec?.releaseOutputBuffer(outputBufferIndex, true)
                return@withContext true
            }

            false
        } catch (e: Exception) {
            Log.e(TAG, "Decode error", e)
            false
        }
    }

    fun release() {
        mediaCodec?.stop()
        mediaCodec?.release()
        mediaCodec = null
    }

    companion object {
        private const val TIMEOUT_US = 10000L  // 10ms超时
        private const val TAG = "HardwareDecoder"
    }
}
```

### 6.5 网络传输优化

#### 6.5.1 零拷贝传输

```csharp
public class ZeroCopyNetworkSender
{
    private Socket _socket;
    private readonly ArrayPool<byte> _bufferPool = ArrayPool<byte>.Shared;

    public async Task SendFrameAsync(EncodedFrame frame)
    {
        // 1. 准备消息头
        var header = CreateMessageHeader(MessageType.VideoFrame, frame.Size);

        // 2. 使用Scatter-Gather I/O (多缓冲区发送)
        var buffers = new List<ArraySegment<byte>>
        {
            new ArraySegment<byte>(header),
            new ArraySegment<byte>(frame.Data)
        };

        // 3. 发送 (零拷贝)
        await _socket.SendAsync(buffers, SocketFlags.None);
    }
}
```

#### 6.5.2 帧缓冲池

```kotlin
class FrameBufferPool(private val bufferSize: Int, poolSize: Int = 10) {
    private val bufferPool = ConcurrentLinkedQueue<ByteArray>()

    init {
        repeat(poolSize) {
            bufferPool.offer(ByteArray(bufferSize))
        }
    }

    fun acquire(): ByteArray {
        return bufferPool.poll() ?: ByteArray(bufferSize)
    }

    fun release(buffer: ByteArray) {
        if (buffer.size == bufferSize) {
            bufferPool.offer(buffer)
        }
    }
}
```

---

## 7. 性能优化方案

### 7.1 延迟优化

#### 7.1.1 端到端延迟分解

```
总延迟 = 捕获延迟 + 编码延迟 + 传输延迟 + 解码延迟 + 渲染延迟

目标: < 100ms (WiFi) / < 50ms (USB)

优化措施:
- 捕获延迟 (5-10ms): 使用DXGI Desktop Duplication，避免GDI捕获
- 编码延迟 (10-20ms): 硬件编码，ultrafast预设
- 传输延迟 (10-30ms): TCP_NODELAY，大窗口，优先级队列
- 解码延迟 (5-10ms): 硬件解码，低延迟模式
- 渲染延迟 (8-16ms): 双缓冲/三缓冲，VSync
```

#### 7.1.2 关键路径优化

```csharp
public class LowLatencyPipeline
{
    private readonly Channel<CapturedFrame> _captureChannel;
    private readonly Channel<EncodedFrame> _encodeChannel;

    public LowLatencyPipeline()
    {
        // 使用有界通道，防止缓冲积累
        _captureChannel = Channel.CreateBounded<CapturedFrame>(
            new BoundedChannelOptions(2)  // 只缓冲1-2帧
            {
                FullMode = BoundedChannelFullMode.DropOldest  // 丢弃旧帧
            });
    }

    // 捕获线程: 高优先级
    private async Task CaptureLoop()
    {
        Thread.CurrentThread.Priority = ThreadPriority.Highest;

        while (_running)
        {
            var frame = _duplicator.CaptureFrame();
            await _captureChannel.Writer.WriteAsync(frame);
        }
    }

    // 编码线程: 高优先级
    private async Task EncodeLoop()
    {
        Thread.CurrentThread.Priority = ThreadPriority.AboveNormal;

        await foreach (var frame in _captureChannel.Reader.ReadAllAsync())
        {
            var encoded = _encoder.Encode(frame);
            await _encodeChannel.Writer.WriteAsync(encoded);
        }
    }
}
```

### 7.2 CPU优化

#### 7.2.1 SIMD加速

```csharp
// 使用System.Runtime.Intrinsics进行SIMD加速
public unsafe void ConvertBGRAToYUV420P_SIMD(byte* src, byte* dst, int width, int height)
{
    // 使用AVX2指令集并行处理
    for (int y = 0; y < height; y += 2)
    {
        for (int x = 0; x < width; x += 16)  // 一次处理16个像素
        {
            var pixels = Avx2.LoadVector256(src + offset);
            // BGRA -> YUV转换
            var y_values = ComputeLuminance(pixels);
            var u_values = ComputeChrominanceU(pixels);
            var v_values = ComputeChrominanceV(pixels);

            Avx2.Store(dst_y + offset, y_values);
            Avx2.Store(dst_u + offset, u_values);
            Avx2.Store(dst_v + offset, v_values);
        }
    }
}
```

### 7.3 内存优化

#### 7.3.1 对象池模式

```kotlin
object FrameObjectPool {
    private val videoFramePool = ArrayDeque<VideoFrame>(capacity = 20)
    private val lock = ReentrantLock()

    fun obtainVideoFrame(): VideoFrame {
        lock.withLock {
            return if (videoFramePool.isNotEmpty()) {
                videoFramePool.removeLast()
            } else {
                VideoFrame()
            }
        }
    }

    fun recycleVideoFrame(frame: VideoFrame) {
        frame.reset()
        lock.withLock {
            if (videoFramePool.size < 20) {
                videoFramePool.addLast(frame)
            }
        }
    }
}
```

### 7.4 电池优化 (Android)

```kotlin
class PowerOptimizer(private val context: Context) {

    fun optimizeForPowerMode(mode: PowerMode) {
        when (mode) {
            PowerMode.POWER_SAVE -> {
                // 降低帧率和分辨率
                updateVideoConfig(
                    maxFps = 30,
                    maxBitrate = 2_000_000,
                    resolution = Resolution.HD_720P
                )

                // 降低屏幕亮度
                reduceScreenBrightness()

                // 使用更低功耗的解码器配置
                useEfficientDecoder()
            }

            PowerMode.BALANCED -> {
                updateVideoConfig(
                    maxFps = 60,
                    maxBitrate = 5_000_000,
                    resolution = Resolution.FHD_1080P
                )
            }

            PowerMode.PERFORMANCE -> {
                updateVideoConfig(
                    maxFps = 120,
                    maxBitrate = 10_000_000,
                    resolution = Resolution.NATIVE
                )
            }
        }
    }

    // 监控电池状态
    fun monitorBatteryLevel() {
        val batteryStatus = context.registerReceiver(null,
            IntentFilter(Intent.ACTION_BATTERY_CHANGED))

        val level = batteryStatus?.getIntExtra(BatteryManager.EXTRA_LEVEL, -1) ?: -1
        val scale = batteryStatus?.getIntExtra(BatteryManager.EXTRA_SCALE, -1) ?: -1

        val batteryPct = level * 100 / scale.toFloat()

        when {
            batteryPct < 15 -> optimizeForPowerMode(PowerMode.POWER_SAVE)
            batteryPct < 30 -> optimizeForPowerMode(PowerMode.BALANCED)
        }
    }
}
```

---

## 8. 安全设计

### 8.1 认证机制

#### 8.1.1 配对认证流程

```
1. 首次连接:
   Android → Windows: 发送设备ID和公钥
   Windows: 显示配对码 (6位数字)
   Android: 用户输入配对码
   Windows: 验证配对码，生成会话密钥
   Windows → Android: 返回加密的会话密钥

2. 后续连接:
   Android → Windows: 发送设备ID + 签名
   Windows: 验证签名
   Windows → Android: 返回新会话密钥
```

#### 8.1.2 实现

```csharp
public class AuthenticationManager
{
    private readonly RSA _serverKey;
    private readonly Dictionary<string, DeviceCredential> _trustedDevices;

    public async Task<AuthResult> AuthenticateDeviceAsync(AuthRequest request)
    {
        // 1. 检查是否是信任设备
        if (_trustedDevices.TryGetValue(request.DeviceId, out var credential))
        {
            // 验证签名
            if (VerifySignature(request.DeviceId, request.Signature, credential.PublicKey))
            {
                var sessionKey = GenerateSessionKey();
                return new AuthResult
                {
                    Success = true,
                    SessionKey = sessionKey,
                    RequiresPairing = false
                };
            }
        }

        // 2. 新设备需要配对
        var pairingCode = GeneratePairingCode();  // 6位数字
        ShowPairingDialog(request.DeviceId, pairingCode);

        return new AuthResult
        {
            Success = false,
            RequiresPairing = true,
            PairingToken = CreatePairingToken(request.DeviceId, pairingCode)
        };
    }

    public async Task<bool> CompletePairingAsync(string deviceId, string pairingCode, byte[] publicKey)
    {
        if (VerifyPairingCode(deviceId, pairingCode))
        {
            // 保存设备凭证
            _trustedDevices[deviceId] = new DeviceCredential
            {
                DeviceId = deviceId,
                PublicKey = publicKey,
                PairedAt = DateTime.UtcNow
            };

            SaveTrustedDevices();
            return true;
        }

        return false;
    }
}
```

### 8.2 数据加密

#### 8.2.1 传输加密

```kotlin
class SecureNetworkManager {
    private var sslSocket: SSLSocket? = null

    suspend fun connectSecure(host: String, port: Int, sessionKey: ByteArray): Result<Unit> {
        return withContext(Dispatchers.IO) {
            try {
                // 1. 创建SSL上下文
                val sslContext = SSLContext.getInstance("TLS")

                // 2. 使用会话密钥初始化
                val keyManager = createKeyManager(sessionKey)
                sslContext.init(arrayOf(keyManager), null, SecureRandom())

                // 3. 创建SSL Socket
                val socketFactory = sslContext.socketFactory
                sslSocket = socketFactory.createSocket(host, port) as SSLSocket

                // 4. 启用强加密套件
                sslSocket?.enabledCipherSuites = arrayOf(
                    "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384",
                    "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"
                )

                // 5. 握手
                sslSocket?.startHandshake()

                Result.success(Unit)
            } catch (e: Exception) {
                Result.failure(e)
            }
        }
    }
}
```

#### 8.2.2 敏感数据保护

```csharp
// Windows端: 使用DPAPI保护本地数据
public class SecureStorage
{
    public void SaveDeviceCredentials(DeviceCredential credential)
    {
        var json = JsonSerializer.Serialize(credential);
        var bytes = Encoding.UTF8.GetBytes(json);

        // 使用DPAPI加密
        var encrypted = ProtectedData.Protect(
            bytes,
            entropy: null,
            scope: DataProtectionScope.CurrentUser);

        File.WriteAllBytes(GetCredentialPath(credential.DeviceId), encrypted);
    }

    public DeviceCredential LoadDeviceCredentials(string deviceId)
    {
        var encrypted = File.ReadAllBytes(GetCredentialPath(deviceId));

        // 解密
        var bytes = ProtectedData.Unprotect(
            encrypted,
            entropy: null,
            scope: DataProtectionScope.CurrentUser);

        var json = Encoding.UTF8.GetString(bytes);
        return JsonSerializer.Deserialize<DeviceCredential>(json);
    }
}
```

```kotlin
// Android端: 使用Keystore保护密钥
class SecureKeyStorage(private val context: Context) {
    private val keyStore = KeyStore.getInstance("AndroidKeyStore").apply {
        load(null)
    }

    fun saveSessionKey(deviceId: String, key: ByteArray) {
        val cipher = getCipher()
        cipher.init(Cipher.ENCRYPT_MODE, getOrCreateKey(deviceId))

        val encrypted = cipher.doFinal(key)
        val iv = cipher.iv

        // 保存到EncryptedSharedPreferences
        val prefs = EncryptedSharedPreferences.create(
            context,
            "secure_keys",
            getMasterKey(),
            EncryptedSharedPreferences.PrefKeyEncryptionScheme.AES256_SIV,
            EncryptedSharedPreferences.PrefValueEncryptionScheme.AES256_GCM
        )

        prefs.edit()
            .putString("${deviceId}_key", Base64.encodeToString(encrypted, Base64.DEFAULT))
            .putString("${deviceId}_iv", Base64.encodeToString(iv, Base64.DEFAULT))
            .apply()
    }

    private fun getOrCreateKey(alias: String): SecretKey {
        if (!keyStore.containsAlias(alias)) {
            val keyGenerator = KeyGenerator.getInstance(
                KeyProperties.KEY_ALGORITHM_AES,
                "AndroidKeyStore"
            )

            keyGenerator.init(
                KeyGenParameterSpec.Builder(
                    alias,
                    KeyProperties.PURPOSE_ENCRYPT or KeyProperties.PURPOSE_DECRYPT
                )
                    .setBlockModes(KeyProperties.BLOCK_MODE_GCM)
                    .setEncryptionPaddings(KeyProperties.ENCRYPTION_PADDING_NONE)
                    .setUserAuthenticationRequired(false)
                    .build()
            )

            keyGenerator.generateKey()
        }

        return keyStore.getKey(alias, null) as SecretKey
    }
}
```

### 8.3 权限控制

#### Android权限清单

```xml
<manifest>
    <!-- 网络权限 -->
    <uses-permission android:name="android.permission.INTERNET" />
    <uses-permission android:name="android.permission.ACCESS_NETWORK_STATE" />
    <uses-permission android:name="android.permission.ACCESS_WIFI_STATE" />
    <uses-permission android:name="android.permission.CHANGE_WIFI_STATE" />

    <!-- USB权限 -->
    <uses-permission android:name="android.permission.USB_PERMISSION" />

    <!-- 保持唤醒 -->
    <uses-permission android:name="android.permission.WAKE_LOCK" />

    <!-- 前台服务 -->
    <uses-permission android:name="android.permission.FOREGROUND_SERVICE" />

    <!-- 通知 -->
    <uses-permission android:name="android.permission.POST_NOTIFICATIONS" />
</manifest>
```

---

## 9. 部署架构

### 9.1 Windows安装包结构

```
ExpandScreen_Setup.exe
├── ExpandScreen.exe              # 主程序
├── ExpandScreenDriver.sys        # 虚拟显示驱动
├── ExpandScreenDriver.inf        # 驱动安装信息
├── ExpandScreenDriver.cat        # 驱动签名
├── adb.exe                       # Android调试桥
├── AdbWinApi.dll                 # ADB Windows API
├── libs/                         # 依赖库
│   ├── ffmpeg.dll
│   ├── avcodec-xx.dll
│   ├── avutil-xx.dll
│   └── ...
└── config/                       # 配置文件
    └── default_settings.json
```

### 9.2 Android APK结构

```
ExpandScreen.apk
├── classes.dex                   # Dalvik字节码
├── lib/                          # 原生库
│   ├── arm64-v8a/
│   │   └── libnative.so
│   ├── armeabi-v7a/
│   │   └── libnative.so
│   └── x86_64/
│       └── libnative.so
├── res/                          # 资源文件
├── assets/                       # 资产文件
└── AndroidManifest.xml           # 清单文件
```

---

## 10. 测试策略

### 10.1 单元测试

```csharp
[TestClass]
public class VideoEncoderTests
{
    [TestMethod]
    public async Task Encode_ShouldReturnValidFrame()
    {
        // Arrange
        var encoder = new FFmpegEncoder();
        var config = new EncoderConfig
        {
            Width = 1920,
            Height = 1080,
            Bitrate = 5_000_000,
            Framerate = 60
        };
        await encoder.InitializeAsync(config);

        var frame = CreateTestFrame(1920, 1080);

        // Act
        var encoded = await encoder.EncodeAsync(frame);

        // Assert
        Assert.IsNotNull(encoded);
        Assert.IsTrue(encoded.Size > 0);
        Assert.AreEqual(frame.Timestamp, encoded.Timestamp);
    }
}
```

### 10.2 集成测试

- 端到端延迟测试
- 多设备连接测试
- 长时间稳定性测试
- 网络异常恢复测试

### 10.3 性能测试

```kotlin
@Test
fun testDecodingPerformance() {
    val decoder = HardwareDecoder(surface)
    decoder.initialize(1920, 1080, MediaFormat.MIMETYPE_VIDEO_AVC)

    val frames = loadTestFrames()  // 1000帧
    val startTime = System.nanoTime()

    frames.forEach { frame ->
        decoder.decode(frame.data)
    }

    val endTime = System.nanoTime()
    val averageFps = frames.size / ((endTime - startTime) / 1_000_000_000.0)

    assertTrue("FPS should be >= 60", averageFps >= 60.0)
}
```

---

## 附录

### A. 性能指标

| 指标 | 目标值 | 测量方法 |
|------|--------|----------|
| 端到端延迟 (WiFi) | < 100ms | 屏幕显示时间戳 - 捕获时间戳 |
| 端到端延迟 (USB) | < 50ms | 同上 |
| 帧率 (1080p) | 60fps | 实际渲染帧数/秒 |
| CPU占用率 | < 30% | Windows任务管理器 |
| 内存占用 (Windows) | < 500MB | 工作集内存 |
| 内存占用 (Android) | < 300MB | Android Profiler |
| 网络带宽 (1080p@60fps) | 5-10 Mbps | 网络监控工具 |

### B. 兼容性矩阵

| Windows版本 | 支持状态 | 备注 |
|-------------|---------|------|
| Windows 11 | 完全支持 | 推荐 |
| Windows 10 (21H2+) | 完全支持 | |
| Windows 10 (20H2) | 部分支持 | 可能需要更新 |

| Android版本 | 支持状态 | 备注 |
|-------------|---------|------|
| Android 13+ | 完全支持 | |
| Android 10-12 | 完全支持 | |
| Android 7-9 | 基础支持 | 部分功能受限 |

### C. 错误码表

| 错误码 | 说明 | 解决方法 |
|--------|------|----------|
| E1001 | 驱动安装失败 | 检查管理员权限 |
| E1002 | 设备连接超时 | 检查网络连接 |
| E1003 | 编码器初始化失败 | 更新显卡驱动 |
| E1004 | 解码器不支持 | 设备硬件不支持 |
| E2001 | 认证失败 | 重新配对设备 |
| E2002 | 会话过期 | 重新连接 |

---

**文档版本**: v1.0
**创建日期**: 2026-01-22
**最后更新**: 2026-01-22
**作者**: ExpandScreen开发团队
